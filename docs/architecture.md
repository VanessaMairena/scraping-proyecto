# üìê Arquitectura del Proyecto

**Nombre del Proyecto:** Scraping Web Din√°mico y Est√°tico con PostgreSQL + Azure OpenAI  
**Autora:** Vanessa Mairena Solano  
**Descripci√≥n:** Este documento explica la arquitectura funcional del sistema desarrollado.

---

## üîÑ Flujo General del Sistema

```
+------------------+      +------------------+       +--------------------+      +------------------+
| Scrapers         | ---> | PostgreSQL DB    |  ---> | JSON Files (API)   | ---> | Frontend (UI)    |
| (Din√°mico y Est.)|      | productos + logs |       | results / files    |      | Dashboard Web    |
+------------------+      +------------------+       +--------------------+      +------------------+

                          +----------------+
                          | Azure OpenAI   |
                          | Selectores LLM |
                          +----------------+
```

---

## üîß M√≥dulos Principales

| M√≥dulo         | Descripci√≥n |
|----------------|-------------|
| `scraper/`     | Contiene `scraper_dynamic.py` (Selenium) y `scraper_static.py` (BeautifulSoup). Extraen productos y archivos. |
| `downloads/`   | Carpeta donde se guardan los archivos descargados. |
| `data/`        | Contiene los archivos `results.json`, `files.json`, `events.json` para mostrar en el frontend. |
| `llm/`         | Analiza productos o genera selectores con el modelo GPT-4o desde Azure OpenAI. |
| `logs/`        | Guarda `scraper.log` con logs estructurados en JSON. |
| `api/`         | API REST desarrollada en Flask para consumir desde JavaScript (frontend). |
| `frontend/`    | HTML5, CSS y JS que muestran productos, archivos y eventos con `fetch()` y FullCalendar.js. |
| `scheduler.py` | Programa la ejecuci√≥n autom√°tica cada 30 minutos usando APScheduler. |
| `.env`         | Variables de entorno (PostgreSQL y claves Azure). |
| `docs/`        | Gu√≠as, respaldo de la BD y documentaci√≥n t√©cnica. |

---

## üß† Integraci√≥n con LLM (Azure OpenAI)

- Utiliza el modelo `gpt-4o-mini` para:
  - Generar selectores CSS/XPath a partir de HTML.
  - Analizar productos y generar respuestas inteligentes.
- Implementado v√≠a API REST (`llm/llm_selector.py`).

---

## üìä Observabilidad y Logs

- Todos los procesos (scraping, errores, cambios) se registran en `logs/scraper.log`.
- Formato: JSON estructurado con campos como:
  - `timestamp`
  - `level`
  - `message`

---

## üîÅ Automatizaci√≥n

- `scheduler.py` ejecuta el scraping din√°mico y est√°tico cada 30 minutos.
- Se actualizan autom√°ticamente:
  - Archivos `results.json` y `files.json`
  - Base de datos `scrapingdb`
  - Carpeta de descargas con verificaci√≥n SHA-256

---

## üîê Seguridad

- Las claves de Azure y PostgreSQL est√°n protegidas mediante `.env`.
- No se exponen directamente en los scripts.

---

## ‚úÖ Final

Este dise√±o modular permite ampliar el sistema f√°cilmente para nuevos sitios web, nuevos formatos de datos o APIs adicionales.