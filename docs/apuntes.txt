 Comentario General del Proyecto: Web Scraping Inteligente con LLM + Dashboard + API REST

El proyecto desarrollado por Vanessa Mairena Solano, Justin Rodr√≠guez Gonz√°lez y Brandon Campos M√©ndez representa una soluci√≥n moderna, integral y altamente funcional para la recolecci√≥n, an√°lisis y visualizaci√≥n de datos web mediante t√©cnicas avanzadas de scraping combinadas con inteligencia artificial. Esta iniciativa, enmarcada dentro del curso de Computaci√≥n en la Nube de la Universidad T√©cnica Nacional, se destaca no solo por su estructura t√©cnica robusta, sino tambi√©n por su enfoque en automatizaci√≥n, escalabilidad y usabilidad real.

Innovaci√≥n T√©cnica con Inteligencia Artificial

Uno de los aspectos m√°s sobresalientes del proyecto es la incorporaci√≥n de Azure OpenAI con el modelo gpt-4o-mini. Esto permite llevar el scraping tradicional al siguiente nivel, generando selectores CSS/XPath de forma automatizada e inteligente, lo cual reduce la necesidad de intervenci√≥n humana en la adaptaci√≥n a cambios estructurales de los sitios web. Tambi√©n se aplica para an√°lisis de productos, lo que representa una fusi√≥n eficaz entre scraping cl√°sico y procesamiento sem√°ntico.

Scraping Din√°mico y Est√°tico

El sistema no se limita a un solo tipo de sitio web. Es capaz de interactuar tanto con p√°ginas est√°ticas (basadas en HTML puro) como con p√°ginas din√°micas que cargan contenido mediante JavaScript, usando Selenium y chromedriver. Esta dualidad ampl√≠a su aplicabilidad en escenarios reales, permitiendo una cobertura amplia de fuentes de datos web.

Automatizaci√≥n con Scheduler

Otro punto fuerte es el uso de APScheduler, que ejecuta tareas de scraping autom√°ticamente cada 30 minutos, garantizando que la base de datos y los archivos del dashboard est√©n siempre actualizados. Esto promueve un enfoque de observabilidad continua y respuesta r√°pida ante cambios en las fuentes externas.

Visualizaci√≥n, API y Logs

El sistema ofrece un dashboard web amigable que consume archivos JSON generados desde el backend, permitiendo la presentaci√≥n clara de resultados. Adem√°s, una API REST en Flask permite que otras aplicaciones accedan a los datos estructurados. Los logs, almacenados en formato JSON estructurado, representan una excelente pr√°ctica de ingenier√≠a para mantener trazabilidad y control sobre el comportamiento del sistema.

üóÑ Base de Datos y Gesti√≥n de Archivos

La base de datos PostgreSQL est√° bien modelada, con tablas para productos y archivos descargados, incluyendo hashes SHA-256 para verificar integridad. Esto proporciona no solo persistencia de datos, sino tambi√©n un mecanismo confiable para detecci√≥n de cambios y gesti√≥n eficiente de versiones de archivos descargados.

Implementaci√≥n Clara y Documentada

El proyecto est√° muy bien organizado y documentado. La estructura por carpetas es clara (scraper/, frontend/, llm/, logs/, api/), y existe una gu√≠a de inicio para facilitar la implementaci√≥n por nuevos usuarios. El uso de variables de entorno en .env y dependencias centralizadas en requirements.txt demuestra buenas pr√°cticas de desarrollo.
