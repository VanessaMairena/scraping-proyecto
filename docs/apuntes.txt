 Comentario General del Proyecto: Web Scraping Inteligente con LLM + Dashboard + API REST

El proyecto desarrollado por Vanessa Mairena Solano, Justin Rodr铆guez Gonz谩lez y Brandon Campos M茅ndez representa una soluci贸n moderna, integral y altamente funcional para la recolecci贸n, an谩lisis y visualizaci贸n de datos web mediante t茅cnicas avanzadas de scraping combinadas con inteligencia artificial. Esta iniciativa, enmarcada dentro del curso de Computaci贸n en la Nube de la Universidad T茅cnica Nacional, se destaca no solo por su estructura t茅cnica robusta, sino tambi茅n por su enfoque en automatizaci贸n, escalabilidad y usabilidad real.

 Innovaci贸n T茅cnica con Inteligencia Artificial

Uno de los aspectos m谩s sobresalientes del proyecto es la incorporaci贸n de Azure OpenAI con el modelo gpt-4o-mini. Esto permite llevar el scraping tradicional al siguiente nivel, generando selectores CSS/XPath de forma automatizada e inteligente, lo cual reduce la necesidad de intervenci贸n humana en la adaptaci贸n a cambios estructurales de los sitios web. Tambi茅n se aplica para an谩lisis de productos, lo que representa una fusi贸n eficaz entre scraping cl谩sico y procesamiento sem谩ntico.

 Scraping Din谩mico y Est谩tico

El sistema no se limita a un solo tipo de sitio web. Es capaz de interactuar tanto con p谩ginas est谩ticas (basadas en HTML puro) como con p谩ginas din谩micas que cargan contenido mediante JavaScript, usando Selenium y chromedriver. Esta dualidad ampl铆a su aplicabilidad en escenarios reales, permitiendo una cobertura amplia de fuentes de datos web.

 Automatizaci贸n con Scheduler

Otro punto fuerte es el uso de APScheduler, que ejecuta tareas de scraping autom谩ticamente cada 30 minutos, garantizando que la base de datos y los archivos del dashboard est茅n siempre actualizados. Esto promueve un enfoque de observabilidad continua y respuesta r谩pida ante cambios en las fuentes externas.

 Visualizaci贸n, API y Logs

El sistema ofrece un dashboard web amigable que consume archivos JSON generados desde el backend, permitiendo la presentaci贸n clara de resultados. Adem谩s, una API REST en Flask permite que otras aplicaciones accedan a los datos estructurados. Los logs, almacenados en formato JSON estructurado, representan una excelente pr谩ctica de ingenier铆a para mantener trazabilidad y control sobre el comportamiento del sistema.

 Base de Datos y Gesti贸n de Archivos

La base de datos PostgreSQL est谩 bien modelada, con tablas para productos y archivos descargados, incluyendo hashes SHA-256 para verificar integridad. Esto proporciona no solo persistencia de datos, sino tambi茅n un mecanismo confiable para detecci贸n de cambios y gesti贸n eficiente de versiones de archivos descargados.

 Implementaci贸n Clara y Documentada

El proyecto est谩 muy bien organizado y documentado. La estructura por carpetas es clara (scraper/, frontend/, llm/, logs/, api/), y existe una gu铆a de inicio para facilitar la implementaci贸n por nuevos usuarios. El uso de variables de entorno en .env y dependencias centralizadas en requirements.txt demuestra buenas pr谩cticas de desarrollo.

 Formaci贸n Acad茅mica y Aplicaci贸n Profesional

Este proyecto no solo cumple con los requisitos acad茅micos, sino que tambi茅n puede ser f谩cilmente extendido para su uso en ambientes reales, como monitoreo de precios, seguimiento de eventos, control de inventarios online, o an谩lisis de competencia. Su desarrollo demuestra la capacidad de los autores para combinar conocimientos de backend, frontend, IA, bases de datos y servicios en la nube en una soluci贸n s贸lida, escalable y funcional.

 Conclusi贸n

En resumen, este proyecto representa un gran ejemplo de integraci贸n tecnol贸gica con objetivos claros y resultados tangibles. La combinaci贸n de scraping, inteligencia artificial, automatizaci贸n y visualizaci贸n lo convierte en una herramienta poderosa y un excelente logro acad茅mico. Es un claro reflejo del nivel t茅cnico alcanzado por sus autores y una excelente carta de presentaci贸n profesional para oportunidades futuras en el 谩rea de desarrollo, an谩lisis de datos o soluciones basadas en IA y nube.

