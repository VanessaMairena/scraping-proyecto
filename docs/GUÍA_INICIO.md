# ğŸ“˜ GUÃA DE INICIO RÃPIDO â€“ Proyecto de Scraping Inteligente

**Autores:** Vanessa Mairena Solano , Jusin Rodriguez Gonzalez, Brandon Campos mendes 
**Carrera:** IngenierÃ­a en TecnologÃ­as de la InformaciÃ³n y ComunicaciÃ³n  
**Universidad:** Universidad TÃ©cnica Nacional  
**Modalidad:** TeÃ³rico â€“ prÃ¡ctico | Grupo 1  


---

## ğŸ“Œ Requisitos Previos

Antes de ejecutar el proyecto, asegÃºrate de tener instalado lo siguiente:

- Python 3.9 o superior  
- PostgreSQL 12 o superior  
- Navegador Google Chrome  
- `chromedriver` compatible con tu versiÃ³n de Chrome  
- Cuenta de Azure con acceso a Azure OpenAI y modelo `gpt-4o-mini`

---

## ğŸ›  InstalaciÃ³n del Proyecto

### 1. Clona el repositorio
```bash
git clone https://github.com/VanessaMairena/scraping-proyecto.git
cd scraping-proyecto
```

### 2. Crea y activa el entorno virtual

En **Windows**:
```bash
python -m venv venv
venv\Scripts\activate
```

En **Linux/Mac**:
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instala las dependencias del proyecto

```bash
pip install -r requirements.txt
```

### 4. Configura el archivo `.env` con tus credenciales

Crea un archivo `.env` en la raÃ­z con lo siguiente:

```env
OPENAI_API_KEY=tu_clave_personal
OPENAI_ENDPOINT=https://voiceflip-openai.openai.azure.com/
MODEL_NAME=gpt-4o-mini
API_VERSION=2025-01-01-preview

DB_HOST=localhost
DB_PORT=5432
DB_NAME=scrapingdb
DB_USER=postgres
DB_PASSWORD=Mairena12
```

---

## ğŸš€ CÃ³mo Ejecutar el Proyecto

| Funcionalidad               | Comando                                              |
|----------------------------|------------------------------------------------------|
| Scraping EstÃ¡tico          | `python scraper/scraper_static.py`                  |
| Scraping DinÃ¡mico          | `python scraper/scraper_dynamic.py`                 |
| API REST JSON              | `python api/json_api_server.py`                     |
| Dashboard Web              | Abre `frontend/index.html` en el navegador          |
| Ejecutar con Scheduler     | `python scheduler.py`                               |
| Generar selectores con LLM | `python llm/llm_selector.py`                        |

---

## ğŸ“‚ Estructura Relevante

```
â”œâ”€â”€ scraper/              # Scrapers dinÃ¡mico y estÃ¡tico
â”œâ”€â”€ llm/                  # Generador de selectores con LLM
â”œâ”€â”€ api/                  # API Flask con salida JSON
â”œâ”€â”€ frontend/             # Interfaz visual en HTML, CSS y JS
â”œâ”€â”€ logs/                 # Logs del sistema en formato JSON
â”œâ”€â”€ data/                 # Archivos JSON exportados
â”œâ”€â”€ downloads/            # Archivos descargados
â”œâ”€â”€ scheduler.py          # Automatizador cada 30 min
â”œâ”€â”€ .env                  # Variables sensibles (no subir a GitHub)
```

---

## ğŸ§  Notas Importantes

- La API se ejecuta localmente en `http://127.0.0.1:5000/api/productos`
- El `scheduler.py` ejecuta ambos scrapers automÃ¡ticamente cada 30 minutos
- El archivo `.env` **nunca debe subirse a GitHub**
- Verifica siempre que `chromedriver.exe` sea compatible con tu versiÃ³n de Chrome
- El dashboard se actualiza con los datos de `data/results.json`

---

## â“ Soporte

Para dudas tÃ©cnicas o errores, puedes contactar a Vanessa Mairena o consultar la documentaciÃ³n tÃ©cnica en el `README.md`.
