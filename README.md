# ğŸ’» Proyecto de Scraping DinÃ¡mico y EstÃ¡tico con PostgreSQL + Azure OpenAI

**Autores:** Vanessa Mairena Solano, Justin Rodriguez Gonzalez, Brandon Campos Mendez 
**Carrera:** IngenierÃ­a en TecnologÃ­as de la InformaciÃ³n y ComunicaciÃ³n  
**Proyecto Final: Web Scraping Inteligente con LLM + Dashboard + API REST**

---

## ğŸ›  DescripciÃ³n General

Este proyecto realiza scraping de sitios web **dinÃ¡micos** (JavaScript) y **estÃ¡ticos** (HTML), almacena los datos en **PostgreSQL**, genera archivos JSON para el **frontend** y utiliza **Azure OpenAI (LLM)** para generar y analizar selectores CSS/XPath automÃ¡ticamente. AdemÃ¡s, incluye un **scheduler cada 30 minutos**, logs estructurados en JSON, y una API REST en Flask para exponer los datos.

---

## ğŸ“¦ Estructura del Proyecto

```
â”œâ”€â”€ api/
â”‚   â””â”€â”€ json_api_server.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ events.json
â”‚   â”œâ”€â”€ files.json
â”‚   â””â”€â”€ results.json
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ GUÃA_INICIO.md
â”œâ”€â”€ downloads/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ main.js
â”‚   â”œâ”€â”€ files.js
â”‚   â”œâ”€â”€ results.js
â”‚   â””â”€â”€ calendar.js
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ llm_selector.py
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ scraper.log
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ scraper_dynamic.py
â”‚   â”œâ”€â”€ scraper_static.py
â”‚   â””â”€â”€ driver/chromedriver.exe
â”œâ”€â”€ scheduler.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âš™ï¸ Requisitos

- Python 3.9+
- PostgreSQL 12+
- Cuenta de Azure OpenAI con modelo `gpt-4o-mini`
- Navegador Chrome + `chromedriver`

---

## ğŸ§ª InstalaciÃ³n y ConfiguraciÃ³n RÃ¡pida

1. Clona el repositorio:
```bash
git clone https://github.com/VanessaMairena/scraping-proyecto.git
cd scraping-proyecto
```

2. Crea y activa entorno virtual:
```bash
python -m venv venv
venv\Scripts\activate  # Windows
```

3. Instala las dependencias:
```bash
pip install -r requirements.txt
```

4. Crea el archivo `.env` con tus variables:

```env
OPENAI_API_KEY=tu_clave_azure
OPENAI_ENDPOINT=https://voiceflip-openai.openai.azure.com/
MODEL_NAME=gpt-4o-mini
API_VERSION=2025-01-01-preview

DB_HOST=localhost
DB_PORT=5432
DB_NAME=scrapingdb
DB_USER=postgres
DB_PASSWORD=Mairena12
```

---

## ğŸš€ Uso

| AcciÃ³n | Comando |
|--------|---------|
| Scraping EstÃ¡tico | `python scraper/scraper_static.py` |
| Scraping DinÃ¡mico | `python scraper/scraper_dynamic.py` |
| Scheduler (cada 30 min) | `python scheduler.py` |
| API REST Flask | `python api/json_api_server.py` |
| Dashboard Web | Abre `frontend/index.html` |
| Generar Selectores con LLM | `python llm/llm_selector.py` |

---

## ğŸ§  Inteligencia Artificial

Se utiliza Azure OpenAI con modelo `gpt-4o-mini` para:
- Generar selectores CSS/XPath dinÃ¡micamente
- Analizar productos scrapeados
- Ejecutar pruebas interactivas en consola

---

## ğŸ§© AutomatizaciÃ³n

Se utiliza APScheduler para ejecutar el scraping automÃ¡ticamente cada 30 minutos, registrando logs y manteniendo actualizado el dashboard y los archivos JSON.

---

## ğŸ“Š Logs y Observabilidad

Los logs se guardan en `logs/scraper.log` en formato JSON estructurado con nivel `INFO`, `WARNING`, `ERROR`.

---

## ğŸ—‚ Descargas y Hashes

Los archivos se descargan desde un sitio estÃ¡tico o JSON (ej: `files.json`) y se verifica su integridad con SHA-256. Si un archivo cambia, se reemplaza; si se elimina del origen, se elimina localmente tambiÃ©n.

---

## ğŸ“ Base de Datos

Se utiliza PostgreSQL con dos tablas principales:

- `productos`: contiene los productos scrapeados
- `downloaded_files`: contiene los archivos descargados con hash y fecha

---

## âœ… CrÃ©ditos

Este proyecto fue desarrollado por **Vanessa Mairena Solano** como parte del curso de ComputaciÃ³n en la Nube en la **Universidad TÃ©cnica Nacional**, Grupo 1.

---

## ğŸ“¸ Video de Evidencia

El video de funcionamiento del sistema se encuentra disponible y adjunto como parte del entregable en Campus Virtual.

---

## ğŸ“¤ Subido a GitHub

Repositorio disponible en: [https://github.com/VanessaMairena/scraping-proyecto](https://github.com/VanessaMairena/scraping-proyecto)
